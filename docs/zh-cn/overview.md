# 概述

Audio2Face是一个实时音频到面部表情动画服务，将流式音频输入转换为同步的面部动画数据。该系统使用先进的机器学习模型提取音频特征并生成相应的面部表情，支持CPU和GPU加速推理以获得最佳性能。

该服务专为虚拟人驱动、直播、视频会议和互动娱乐平台等需要低延迟音频到面部转换的实时应用而设计。

## 主要特性

- **实时流式处理**：实时处理音频块，为直播应用提供低延迟
- **双推理引擎**：支持基于ONNX的Unitalker和基于PyTorch的特征提取
- **GPU加速**：支持CUDA 12.1，在NVIDIA GPU上实现高性能推理
- **全面后处理**：9个后处理模块，包括blendshape裁剪、缩放、阈值处理和自定义眨眼动画
- **灵活音频分割**：基于能量的静音检测，实现智能音频分割
- **WebSocket API**：基于FastAPI的流式接口，使用Protocol Buffers序列化
- **Docker支持**：预构建的CPU和CUDA环境Docker镜像
- **可配置管道**：模块化架构，允许自定义后处理管道配置
- **多线程处理**：异步处理，支持可配置的工作池
- **全面测试**：使用pytest和异步测试支持的完整测试覆盖

## 系统架构

系统由以下几个关键组件组成：

- **流式API层**：基于FastAPI的WebSocket服务器，处理实时音频流请求
- **特征提取**：使用Wav2Vec2模型通过PyTorch或ONNX运行时进行音频特征提取
- **推理引擎**：基于ONNX的Unitalker模型，用于音频到blendshape转换
- **音频分割**：基于能量的静音检测，实现智能音频分割
- **后处理管道**：模块化后处理系统，包含9个专用模块：
  - Blendshape裁剪、缩放和阈值处理
  - 自定义眨眼动画注入
  - 线性和指数混合
  - 偏移调整和名称映射
- **数据结构**：FaceClip类，用于管理面部动画数据和格式转换
- **配置系统**：灵活的配置管理，支持不同部署场景
- **日志和监控**：全面的日志记录，支持AWS CloudWatch集成

